{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"softmax.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"t5yj-jeN0b9r","executionInfo":{"status":"ok","timestamp":1602601148764,"user_tz":-180,"elapsed":68613,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"1a6773f4-421a-4469-8edb-c29f1dfd0348","colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","# enter the foldername in your Drive where you have saved the unzipped\n","# 'cs231n' folder containing the '.py', 'classifiers' and 'datasets'\n","# folders.\n","# e.g. 'cs231n/assignments/assignment1/cs231n/'\n","FOLDERNAME = 'cs231n/assignments/assignment1/cs231n/'\n","\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","%cd drive/My\\ Drive\n","%cp -r $FOLDERNAME ../../\n","%cd ../../\n","%cd cs231n/datasets/\n","!bash get_datasets.sh\n","%cd ../../"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/My Drive\n","/content\n","/content/cs231n/datasets\n","--2020-10-13 14:59:02--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  56.8MB/s    in 2.9s    \n","\n","2020-10-13 14:59:05 (56.8 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n","cifar-10-batches-py/\n","cifar-10-batches-py/data_batch_4\n","cifar-10-batches-py/readme.html\n","cifar-10-batches-py/test_batch\n","cifar-10-batches-py/data_batch_3\n","cifar-10-batches-py/batches.meta\n","cifar-10-batches-py/data_batch_2\n","cifar-10-batches-py/data_batch_5\n","cifar-10-batches-py/data_batch_1\n","/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"tags":["pdf-title"],"id":"diS2P8NY0b-B"},"source":["# Softmax exercise\n","\n","*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n","\n","This exercise is analogous to the SVM exercise. You will:\n","\n","- implement a fully-vectorized **loss function** for the Softmax classifier\n","- implement the fully-vectorized expression for its **analytic gradient**\n","- **check your implementation** with numerical gradient\n","- use a validation set to **tune the learning rate and regularization** strength\n","- **optimize** the loss function with **SGD**\n","- **visualize** the final learned weights\n"]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"sy-a0DCS0b-C","executionInfo":{"status":"ok","timestamp":1602601161516,"user_tz":-180,"elapsed":1148,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}}},"source":["import random\n","import numpy as np\n","from cs231n.data_utils import load_CIFAR10\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading extenrnal modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"u_Iykx2c0b-I","executionInfo":{"status":"ok","timestamp":1602601191777,"user_tz":-180,"elapsed":3387,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"92c7f93d-43ab-4a67-bcae-8e2553635192","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n","    \"\"\"\n","    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n","    it for the linear classifier. These are the same steps as we used for the\n","    SVM, but condensed to a single function.  \n","    \"\"\"\n","    # Load the raw CIFAR-10 data\n","    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n","    \n","    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n","    try:\n","       del X_train, y_train\n","       del X_test, y_test\n","       print('Clear previously loaded data.')\n","    except:\n","       pass\n","\n","    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","    \n","    # subsample the data\n","    mask = list(range(num_training, num_training + num_validation))\n","    X_val = X_train[mask]\n","    y_val = y_train[mask]\n","    mask = list(range(num_training))\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","    mask = list(range(num_test))\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","    mask = np.random.choice(num_training, num_dev, replace=False)\n","    X_dev = X_train[mask]\n","    y_dev = y_train[mask]\n","    \n","    # Preprocessing: reshape the image data into rows\n","    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n","    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n","    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n","    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n","    \n","    # Normalize the data: subtract the mean image\n","    mean_image = np.mean(X_train, axis = 0)\n","    X_train -= mean_image\n","    X_val -= mean_image\n","    X_test -= mean_image\n","    X_dev -= mean_image\n","    \n","    # add bias dimension and transform into columns\n","    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n","    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n","    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n","    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n","    \n","    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n","\n","\n","# Invoke the above function to get our data.\n","X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n","print('Train data shape: ', X_train.shape)\n","print('Train labels shape: ', y_train.shape)\n","print('Validation data shape: ', X_val.shape)\n","print('Validation labels shape: ', y_val.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)\n","print('dev data shape: ', X_dev.shape)\n","print('dev labels shape: ', y_dev.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Train data shape:  (49000, 3073)\n","Train labels shape:  (49000,)\n","Validation data shape:  (1000, 3073)\n","Validation labels shape:  (1000,)\n","Test data shape:  (1000, 3073)\n","Test labels shape:  (1000,)\n","dev data shape:  (500, 3073)\n","dev labels shape:  (500,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U4Nskv7t0b-Q"},"source":["## Softmax Classifier\n","\n","Your code for this section will all be written inside `cs231n/classifiers/softmax.py`.\n"]},{"cell_type":"code","metadata":{"id":"-CLAaftN0b-R","executionInfo":{"status":"ok","timestamp":1602611559250,"user_tz":-180,"elapsed":1516,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"a2c5ff27-0732-42f0-ea3e-1121aa0bfd08","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# First implement the naive softmax loss function with nested loops.\n","# Open the file cs231n/classifiers/softmax.py and implement the\n","# softmax_loss_naive function.\n","\n","from cs231n.classifiers.softmax import softmax_loss_naive\n","import time\n","\n","# Generate a random softmax weight matrix and use it to compute the loss.\n","W = np.random.randn(3073, 10) * 0.0001\n","loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n","\n","# As a rough sanity check, our loss should be something close to -log(0.1).\n","print('loss: %f' % loss)\n","print('sanity check: %f' % (-np.log(0.1)))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["loss: 2.377851\n","sanity check: 2.302585\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"tags":["pdf-inline"],"id":"vyHwZmWv0b-Y"},"source":["**Inline Question 1**\n","\n","Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n","\n","$\\color{blue}{\\textit Your Answer:}$ Since this is the first time loss is calculated after W is initialized, and there are 10 classes, then on average the \"chance\" probability of 1 class is 1/10. \n","\n"]},{"cell_type":"code","metadata":{"id":"8-BfQPgV0b-a","executionInfo":{"status":"ok","timestamp":1602611937239,"user_tz":-180,"elapsed":4975,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"29d895b4-3631-42aa-89ec-86c0d5777b0c","colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["# Complete the implementation of softmax_loss_naive and implement a (naive)\n","# version of the gradient that uses nested loops.\n","loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n","\n","# As we did for the SVM, use numeric gradient checking as a debugging tool.\n","# The numeric gradient should be close to the analytic gradient.\n","from cs231n.gradient_check import grad_check_sparse\n","f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n","grad_numerical = grad_check_sparse(f, W, grad, 10)\n","\n","# similar to SVM case, do another gradient check with regularization\n","loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n","f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n","grad_numerical = grad_check_sparse(f, W, grad, 10)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["numerical: 0.706054 analytic: 0.706054, relative error: 9.102097e-08\n","numerical: 2.593558 analytic: 2.593558, relative error: 3.125121e-08\n","numerical: -2.293972 analytic: -2.293972, relative error: 9.279757e-09\n","numerical: 0.434714 analytic: 0.434713, relative error: 2.702927e-07\n","numerical: 0.198997 analytic: 0.198997, relative error: 5.745052e-07\n","numerical: -0.277773 analytic: -0.277773, relative error: 2.189060e-07\n","numerical: 0.681516 analytic: 0.681516, relative error: 9.413831e-09\n","numerical: 0.337876 analytic: 0.337876, relative error: 2.791269e-07\n","numerical: 1.472303 analytic: 1.472303, relative error: 5.636129e-08\n","numerical: -2.208560 analytic: -2.208560, relative error: 4.417398e-09\n","numerical: -0.395296 analytic: -0.395296, relative error: 6.203015e-08\n","numerical: -1.222764 analytic: -1.222765, relative error: 5.438949e-08\n","numerical: -0.068255 analytic: -0.068255, relative error: 9.048490e-07\n","numerical: 0.877537 analytic: 0.877537, relative error: 1.600207e-08\n","numerical: -2.671916 analytic: -2.671916, relative error: 2.703203e-08\n","numerical: -0.285910 analytic: -0.285910, relative error: 1.536140e-07\n","numerical: 2.194905 analytic: 2.194905, relative error: 2.763955e-09\n","numerical: 1.323829 analytic: 1.323829, relative error: 3.809478e-08\n","numerical: -0.526282 analytic: -0.526282, relative error: 4.184073e-08\n","numerical: -1.296076 analytic: -1.296076, relative error: 5.921162e-09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VgSgx9w20b-i","executionInfo":{"status":"ok","timestamp":1602622659949,"user_tz":-180,"elapsed":805,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"00f6627a-9f30-4a43-fa95-4f58470e825d","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Now that we have a naive implementation of the softmax loss function and its gradient,\n","# implement a vectorized version in softmax_loss_vectorized.\n","# The two versions should compute the same results, but the vectorized version should be\n","# much faster.\n","tic = time.time()\n","loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n","toc = time.time()\n","print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n","\n","from cs231n.classifiers.softmax import softmax_loss_vectorized\n","tic = time.time()\n","loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n","toc = time.time()\n","print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n","\n","# As we did for the SVM, we use the Frobenius norm to compare the two versions\n","# of the gradient.\n","grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n","print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n","print('Gradient difference: %f' % grad_difference)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["naive loss: 2.377851e+00 computed in 0.100718s\n","vectorized loss: 2.377851e+00 computed in 0.012075s\n","Loss difference: 0.000000\n","Gradient difference: 0.000000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tuning","tags":["code"],"executionInfo":{"status":"ok","timestamp":1602624177615,"user_tz":-180,"elapsed":710050,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"1cd279d2-b812-453a-a62d-a215b0b64b11","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Use the validation set to tune hyperparameters (regularization strength and\n","# learning rate). You should experiment with different ranges for the learning\n","# rates and regularization strengths; if you are careful you should be able to\n","# get a classification accuracy of over 0.35 on the validation set.\n","\n","from cs231n.classifiers import Softmax\n","results = {}\n","best_val = -1\n","best_softmax = None\n","\n","################################################################################\n","# TODO:                                                                        #\n","# Use the validation set to set the learning rate and regularization strength. #\n","# This should be identical to the validation that you did for the SVM; save    #\n","# the best trained softmax classifer in best_softmax.                          #\n","################################################################################\n","\n","# Provided as a reference. You may or may not want to change these hyperparameters\n","learning_rates = [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-5, 1e-4]\n","regularization_strengths = [2e4, 2.5e4, 3e4, 3.5e4, 4e4, 4.5e4, 5e4, 6e4]\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","def predict_n_evaluate(cls, X, y):\n","  y_pred = cls.predict(X)\n","  accuracy = np.mean(y == y_pred)\n","  return accuracy\n","\n","for lr in learning_rates:\n","  for reg in regularization_strengths:\n","    softmax_cls = Softmax()\n","    print('learning rate: {}, regularization: {}'.format(lr, reg))\n","    loss_hist = softmax_cls.train(X_train, y_train, learning_rate=lr, reg=reg,\n","                      num_iters=1500, verbose=True)\n","    train_accuracy = predict_n_evaluate(softmax_cls, X_train, y_train)\n","    val_accuracy = predict_n_evaluate(softmax_cls, X_val, y_val)\n","    results[(lr, reg)] = (train_accuracy, val_accuracy)\n","    if val_accuracy > best_val:\n","      best_val = val_accuracy\n","      best_softmax = softmax_cls\n","pass\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    \n","# Print out results.\n","for lr, reg in sorted(results):\n","    train_accuracy, val_accuracy = results[(lr, reg)]\n","    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n","                lr, reg, train_accuracy, val_accuracy))\n","    \n","print('best validation accuracy achieved during cross-validation: %f' % best_val)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["learning rate: 1e-09, regularization: 20000.0\n","iteration 0 / 1500: loss 613.127419\n","iteration 100 / 1500: loss 608.147389\n","iteration 200 / 1500: loss 603.394155\n","iteration 300 / 1500: loss 598.567419\n","iteration 400 / 1500: loss 593.352483\n","iteration 500 / 1500: loss 589.475672\n","iteration 600 / 1500: loss 584.300505\n","iteration 700 / 1500: loss 579.638814\n","iteration 800 / 1500: loss 574.858313\n","iteration 900 / 1500: loss 570.860146\n","iteration 1000 / 1500: loss 565.823971\n","iteration 1100 / 1500: loss 561.454114\n","iteration 1200 / 1500: loss 557.293743\n","iteration 1300 / 1500: loss 552.553244\n","iteration 1400 / 1500: loss 548.106899\n","learning rate: 1e-09, regularization: 25000.0\n","iteration 0 / 1500: loss 767.075692\n","iteration 100 / 1500: loss 759.695632\n","iteration 200 / 1500: loss 752.278260\n","iteration 300 / 1500: loss 744.429563\n","iteration 400 / 1500: loss 737.208519\n","iteration 500 / 1500: loss 729.609912\n","iteration 600 / 1500: loss 722.723891\n","iteration 700 / 1500: loss 715.548653\n","iteration 800 / 1500: loss 708.476867\n","iteration 900 / 1500: loss 701.059065\n","iteration 1000 / 1500: loss 694.256074\n","iteration 1100 / 1500: loss 687.274837\n","iteration 1200 / 1500: loss 680.316845\n","iteration 1300 / 1500: loss 673.639781\n","iteration 1400 / 1500: loss 666.771267\n","learning rate: 1e-09, regularization: 30000.0\n","iteration 0 / 1500: loss 916.531022\n","iteration 100 / 1500: loss 906.089603\n","iteration 200 / 1500: loss 894.912866\n","iteration 300 / 1500: loss 883.981183\n","iteration 400 / 1500: loss 873.331608\n","iteration 500 / 1500: loss 862.626415\n","iteration 600 / 1500: loss 852.822719\n","iteration 700 / 1500: loss 842.139956\n","iteration 800 / 1500: loss 832.565166\n","iteration 900 / 1500: loss 822.434818\n","iteration 1000 / 1500: loss 812.878777\n","iteration 1100 / 1500: loss 802.784598\n","iteration 1200 / 1500: loss 793.504691\n","iteration 1300 / 1500: loss 783.845352\n","iteration 1400 / 1500: loss 774.564437\n","learning rate: 1e-09, regularization: 35000.0\n","iteration 0 / 1500: loss 1081.194041\n","iteration 100 / 1500: loss 1065.603753\n","iteration 200 / 1500: loss 1051.920031\n","iteration 300 / 1500: loss 1036.946737\n","iteration 400 / 1500: loss 1021.988535\n","iteration 500 / 1500: loss 1007.979041\n","iteration 600 / 1500: loss 994.255238\n","iteration 700 / 1500: loss 980.413118\n","iteration 800 / 1500: loss 966.861591\n","iteration 900 / 1500: loss 953.284538\n","iteration 1000 / 1500: loss 940.050267\n","iteration 1100 / 1500: loss 926.384749\n","iteration 1200 / 1500: loss 914.237380\n","iteration 1300 / 1500: loss 901.047139\n","iteration 1400 / 1500: loss 889.202856\n","learning rate: 1e-09, regularization: 40000.0\n","iteration 0 / 1500: loss 1248.034671\n","iteration 100 / 1500: loss 1227.933686\n","iteration 200 / 1500: loss 1208.177088\n","iteration 300 / 1500: loss 1189.631351\n","iteration 400 / 1500: loss 1170.278772\n","iteration 500 / 1500: loss 1151.838593\n","iteration 600 / 1500: loss 1133.198478\n","iteration 700 / 1500: loss 1115.689947\n","iteration 800 / 1500: loss 1097.627155\n","iteration 900 / 1500: loss 1080.408592\n","iteration 1000 / 1500: loss 1063.129443\n","iteration 1100 / 1500: loss 1046.437902\n","iteration 1200 / 1500: loss 1029.616590\n","iteration 1300 / 1500: loss 1013.540758\n","iteration 1400 / 1500: loss 997.327852\n","learning rate: 1e-09, regularization: 45000.0\n","iteration 0 / 1500: loss 1383.387182\n","iteration 100 / 1500: loss 1358.919941\n","iteration 200 / 1500: loss 1334.867315\n","iteration 300 / 1500: loss 1310.860786\n","iteration 400 / 1500: loss 1287.280228\n","iteration 500 / 1500: loss 1264.658136\n","iteration 600 / 1500: loss 1241.535268\n","iteration 700 / 1500: loss 1219.582866\n","iteration 800 / 1500: loss 1198.046340\n","iteration 900 / 1500: loss 1176.538309\n","iteration 1000 / 1500: loss 1156.007068\n","iteration 1100 / 1500: loss 1135.011750\n","iteration 1200 / 1500: loss 1114.803081\n","iteration 1300 / 1500: loss 1094.833722\n","iteration 1400 / 1500: loss 1074.976412\n","learning rate: 1e-09, regularization: 50000.0\n","iteration 0 / 1500: loss 1557.505978\n","iteration 100 / 1500: loss 1526.727874\n","iteration 200 / 1500: loss 1495.927735\n","iteration 300 / 1500: loss 1466.711813\n","iteration 400 / 1500: loss 1437.702061\n","iteration 500 / 1500: loss 1409.357314\n","iteration 600 / 1500: loss 1381.262301\n","iteration 700 / 1500: loss 1353.807355\n","iteration 800 / 1500: loss 1326.866740\n","iteration 900 / 1500: loss 1300.527237\n","iteration 1000 / 1500: loss 1274.977297\n","iteration 1100 / 1500: loss 1249.550723\n","iteration 1200 / 1500: loss 1224.804518\n","iteration 1300 / 1500: loss 1200.819054\n","iteration 1400 / 1500: loss 1177.203867\n","learning rate: 1e-09, regularization: 60000.0\n","iteration 0 / 1500: loss 1846.199839\n","iteration 100 / 1500: loss 1802.727339\n","iteration 200 / 1500: loss 1760.135424\n","iteration 300 / 1500: loss 1717.649051\n","iteration 400 / 1500: loss 1676.774083\n","iteration 500 / 1500: loss 1637.331102\n","iteration 600 / 1500: loss 1598.573512\n","iteration 700 / 1500: loss 1560.953453\n","iteration 800 / 1500: loss 1523.491997\n","iteration 900 / 1500: loss 1487.249306\n","iteration 1000 / 1500: loss 1452.603668\n","iteration 1100 / 1500: loss 1417.467500\n","iteration 1200 / 1500: loss 1384.002465\n","iteration 1300 / 1500: loss 1351.112929\n","iteration 1400 / 1500: loss 1319.135516\n","learning rate: 1e-08, regularization: 20000.0\n","iteration 0 / 1500: loss 607.361487\n","iteration 100 / 1500: loss 560.485170\n","iteration 200 / 1500: loss 516.917638\n","iteration 300 / 1500: loss 477.415929\n","iteration 400 / 1500: loss 440.475944\n","iteration 500 / 1500: loss 406.827844\n","iteration 600 / 1500: loss 375.357736\n","iteration 700 / 1500: loss 346.605372\n","iteration 800 / 1500: loss 320.101284\n","iteration 900 / 1500: loss 295.633799\n","iteration 1000 / 1500: loss 272.819683\n","iteration 1100 / 1500: loss 251.950353\n","iteration 1200 / 1500: loss 232.661519\n","iteration 1300 / 1500: loss 214.734134\n","iteration 1400 / 1500: loss 198.542394\n","learning rate: 1e-08, regularization: 25000.0\n","iteration 0 / 1500: loss 771.520474\n","iteration 100 / 1500: loss 697.837310\n","iteration 200 / 1500: loss 631.338963\n","iteration 300 / 1500: loss 570.961402\n","iteration 400 / 1500: loss 516.790224\n","iteration 500 / 1500: loss 467.765631\n","iteration 600 / 1500: loss 422.900510\n","iteration 700 / 1500: loss 382.947596\n","iteration 800 / 1500: loss 346.543536\n","iteration 900 / 1500: loss 313.770149\n","iteration 1000 / 1500: loss 283.707497\n","iteration 1100 / 1500: loss 257.069724\n","iteration 1200 / 1500: loss 232.811446\n","iteration 1300 / 1500: loss 210.609576\n","iteration 1400 / 1500: loss 190.815966\n","learning rate: 1e-08, regularization: 30000.0\n","iteration 0 / 1500: loss 926.822774\n","iteration 100 / 1500: loss 821.707395\n","iteration 200 / 1500: loss 728.978568\n","iteration 300 / 1500: loss 646.117098\n","iteration 400 / 1500: loss 573.067648\n","iteration 500 / 1500: loss 507.907530\n","iteration 600 / 1500: loss 450.625022\n","iteration 700 / 1500: loss 399.645726\n","iteration 800 / 1500: loss 354.419540\n","iteration 900 / 1500: loss 314.588399\n","iteration 1000 / 1500: loss 278.883169\n","iteration 1100 / 1500: loss 247.483455\n","iteration 1200 / 1500: loss 219.721296\n","iteration 1300 / 1500: loss 194.994840\n","iteration 1400 / 1500: loss 173.190918\n","learning rate: 1e-08, regularization: 35000.0\n","iteration 0 / 1500: loss 1068.434231\n","iteration 100 / 1500: loss 927.847296\n","iteration 200 / 1500: loss 806.530580\n","iteration 300 / 1500: loss 701.069219\n","iteration 400 / 1500: loss 609.592102\n","iteration 500 / 1500: loss 529.884344\n","iteration 600 / 1500: loss 460.561013\n","iteration 700 / 1500: loss 400.545795\n","iteration 800 / 1500: loss 348.204781\n","iteration 900 / 1500: loss 302.961754\n","iteration 1000 / 1500: loss 263.526804\n","iteration 1100 / 1500: loss 229.246136\n","iteration 1200 / 1500: loss 199.466617\n","iteration 1300 / 1500: loss 173.664364\n","iteration 1400 / 1500: loss 151.193671\n","learning rate: 1e-08, regularization: 40000.0\n","iteration 0 / 1500: loss 1230.209882\n","iteration 100 / 1500: loss 1048.323352\n","iteration 200 / 1500: loss 893.062151\n","iteration 300 / 1500: loss 761.189947\n","iteration 400 / 1500: loss 648.837362\n","iteration 500 / 1500: loss 553.083998\n","iteration 600 / 1500: loss 471.165027\n","iteration 700 / 1500: loss 401.662304\n","iteration 800 / 1500: loss 342.547874\n","iteration 900 / 1500: loss 292.002653\n","iteration 1000 / 1500: loss 249.249335\n","iteration 1100 / 1500: loss 212.485269\n","iteration 1200 / 1500: loss 181.270059\n","iteration 1300 / 1500: loss 154.776130\n","iteration 1400 / 1500: loss 132.339999\n","learning rate: 1e-08, regularization: 45000.0\n","iteration 0 / 1500: loss 1402.672026\n","iteration 100 / 1500: loss 1171.414195\n","iteration 200 / 1500: loss 978.692241\n","iteration 300 / 1500: loss 817.512484\n","iteration 400 / 1500: loss 682.830061\n","iteration 500 / 1500: loss 570.398084\n","iteration 600 / 1500: loss 476.655086\n","iteration 700 / 1500: loss 398.387060\n","iteration 800 / 1500: loss 332.840168\n","iteration 900 / 1500: loss 278.413583\n","iteration 1000 / 1500: loss 232.615762\n","iteration 1100 / 1500: loss 194.663301\n","iteration 1200 / 1500: loss 162.867937\n","iteration 1300 / 1500: loss 136.338756\n","iteration 1400 / 1500: loss 114.262959\n","learning rate: 1e-08, regularization: 50000.0\n","iteration 0 / 1500: loss 1569.985360\n","iteration 100 / 1500: loss 1285.124374\n","iteration 200 / 1500: loss 1051.936171\n","iteration 300 / 1500: loss 861.226356\n","iteration 400 / 1500: loss 705.210458\n","iteration 500 / 1500: loss 577.151950\n","iteration 600 / 1500: loss 472.890243\n","iteration 700 / 1500: loss 387.550165\n","iteration 800 / 1500: loss 317.398496\n","iteration 900 / 1500: loss 260.077136\n","iteration 1000 / 1500: loss 213.242196\n","iteration 1100 / 1500: loss 174.969896\n","iteration 1200 / 1500: loss 143.632230\n","iteration 1300 / 1500: loss 117.840531\n","iteration 1400 / 1500: loss 96.871449\n","learning rate: 1e-08, regularization: 60000.0\n","iteration 0 / 1500: loss 1822.930453\n","iteration 100 / 1500: loss 1433.528255\n","iteration 200 / 1500: loss 1127.388154\n","iteration 300 / 1500: loss 886.849417\n","iteration 400 / 1500: loss 697.789284\n","iteration 500 / 1500: loss 548.677366\n","iteration 600 / 1500: loss 431.854839\n","iteration 700 / 1500: loss 340.150082\n","iteration 800 / 1500: loss 267.709577\n","iteration 900 / 1500: loss 211.013592\n","iteration 1000 / 1500: loss 166.322805\n","iteration 1100 / 1500: loss 131.227164\n","iteration 1200 / 1500: loss 103.633528\n","iteration 1300 / 1500: loss 82.073029\n","iteration 1400 / 1500: loss 64.856541\n","learning rate: 1e-07, regularization: 20000.0\n","iteration 0 / 1500: loss 617.477995\n","iteration 100 / 1500: loss 276.769937\n","iteration 200 / 1500: loss 124.808225\n","iteration 300 / 1500: loss 57.003365\n","iteration 400 / 1500: loss 26.681738\n","iteration 500 / 1500: loss 13.128837\n","iteration 600 / 1500: loss 6.987074\n","iteration 700 / 1500: loss 4.314194\n","iteration 800 / 1500: loss 3.063422\n","iteration 900 / 1500: loss 2.515846\n","iteration 1000 / 1500: loss 2.294896\n","iteration 1100 / 1500: loss 2.199152\n","iteration 1200 / 1500: loss 2.087412\n","iteration 1300 / 1500: loss 2.082187\n","iteration 1400 / 1500: loss 2.083021\n","learning rate: 1e-07, regularization: 25000.0\n","iteration 0 / 1500: loss 775.784506\n","iteration 100 / 1500: loss 284.723966\n","iteration 200 / 1500: loss 105.470615\n","iteration 300 / 1500: loss 39.881680\n","iteration 400 / 1500: loss 15.888858\n","iteration 500 / 1500: loss 7.173185\n","iteration 600 / 1500: loss 3.941278\n","iteration 700 / 1500: loss 2.764984\n","iteration 800 / 1500: loss 2.302087\n","iteration 900 / 1500: loss 2.228932\n","iteration 1000 / 1500: loss 2.050695\n","iteration 1100 / 1500: loss 2.048501\n","iteration 1200 / 1500: loss 2.094847\n","iteration 1300 / 1500: loss 2.186612\n","iteration 1400 / 1500: loss 2.094489\n","learning rate: 1e-07, regularization: 30000.0\n","iteration 0 / 1500: loss 932.571899\n","iteration 100 / 1500: loss 280.401161\n","iteration 200 / 1500: loss 85.279911\n","iteration 300 / 1500: loss 26.921923\n","iteration 400 / 1500: loss 9.661141\n","iteration 500 / 1500: loss 4.425387\n","iteration 600 / 1500: loss 2.774530\n","iteration 700 / 1500: loss 2.248561\n","iteration 800 / 1500: loss 2.158877\n","iteration 900 / 1500: loss 2.135006\n","iteration 1000 / 1500: loss 2.074040\n","iteration 1100 / 1500: loss 2.062577\n","iteration 1200 / 1500: loss 2.124403\n","iteration 1300 / 1500: loss 2.091812\n","iteration 1400 / 1500: loss 2.080667\n","learning rate: 1e-07, regularization: 35000.0\n","iteration 0 / 1500: loss 1076.209755\n","iteration 100 / 1500: loss 264.747696\n","iteration 200 / 1500: loss 66.431175\n","iteration 300 / 1500: loss 17.819490\n","iteration 400 / 1500: loss 5.975184\n","iteration 500 / 1500: loss 3.055470\n","iteration 600 / 1500: loss 2.366118\n","iteration 700 / 1500: loss 2.162454\n","iteration 800 / 1500: loss 2.189180\n","iteration 900 / 1500: loss 2.088665\n","iteration 1000 / 1500: loss 2.108415\n","iteration 1100 / 1500: loss 2.107274\n","iteration 1200 / 1500: loss 2.077789\n","iteration 1300 / 1500: loss 2.108207\n","iteration 1400 / 1500: loss 2.099209\n","learning rate: 1e-07, regularization: 40000.0\n","iteration 0 / 1500: loss 1229.119643\n","iteration 100 / 1500: loss 247.353824\n","iteration 200 / 1500: loss 51.085116\n","iteration 300 / 1500: loss 11.950803\n","iteration 400 / 1500: loss 4.101719\n","iteration 500 / 1500: loss 2.472865\n","iteration 600 / 1500: loss 2.158369\n","iteration 700 / 1500: loss 2.163528\n","iteration 800 / 1500: loss 2.152566\n","iteration 900 / 1500: loss 2.172206\n","iteration 1000 / 1500: loss 2.142684\n","iteration 1100 / 1500: loss 2.120927\n","iteration 1200 / 1500: loss 2.108015\n","iteration 1300 / 1500: loss 2.137648\n","iteration 1400 / 1500: loss 2.193687\n","learning rate: 1e-07, regularization: 45000.0\n","iteration 0 / 1500: loss 1371.466077\n","iteration 100 / 1500: loss 225.826898\n","iteration 200 / 1500: loss 38.675695\n","iteration 300 / 1500: loss 8.113686\n","iteration 400 / 1500: loss 3.172730\n","iteration 500 / 1500: loss 2.308784\n","iteration 600 / 1500: loss 2.120489\n","iteration 700 / 1500: loss 2.194154\n","iteration 800 / 1500: loss 2.111322\n","iteration 900 / 1500: loss 2.112961\n","iteration 1000 / 1500: loss 2.118527\n","iteration 1100 / 1500: loss 2.145507\n","iteration 1200 / 1500: loss 2.131338\n","iteration 1300 / 1500: loss 2.151501\n","iteration 1400 / 1500: loss 2.077730\n","learning rate: 1e-07, regularization: 50000.0\n","iteration 0 / 1500: loss 1561.069969\n","iteration 100 / 1500: loss 210.181588\n","iteration 200 / 1500: loss 29.852413\n","iteration 300 / 1500: loss 5.848510\n","iteration 400 / 1500: loss 2.657410\n","iteration 500 / 1500: loss 2.170726\n","iteration 600 / 1500: loss 2.118571\n","iteration 700 / 1500: loss 2.202324\n","iteration 800 / 1500: loss 2.166768\n","iteration 900 / 1500: loss 2.148882\n","iteration 1000 / 1500: loss 2.174148\n","iteration 1100 / 1500: loss 2.156722\n","iteration 1200 / 1500: loss 2.125636\n","iteration 1300 / 1500: loss 2.109059\n","iteration 1400 / 1500: loss 2.115175\n","learning rate: 1e-07, regularization: 60000.0\n","iteration 0 / 1500: loss 1868.616628\n","iteration 100 / 1500: loss 168.574197\n","iteration 200 / 1500: loss 17.006982\n","iteration 300 / 1500: loss 3.475606\n","iteration 400 / 1500: loss 2.277230\n","iteration 500 / 1500: loss 2.191847\n","iteration 600 / 1500: loss 2.160060\n","iteration 700 / 1500: loss 2.133993\n","iteration 800 / 1500: loss 2.141115\n","iteration 900 / 1500: loss 2.167718\n","iteration 1000 / 1500: loss 2.177251\n","iteration 1100 / 1500: loss 2.156818\n","iteration 1200 / 1500: loss 2.113813\n","iteration 1300 / 1500: loss 2.207652\n","iteration 1400 / 1500: loss 2.108167\n","learning rate: 1e-06, regularization: 20000.0\n","iteration 0 / 1500: loss 620.490806\n","iteration 100 / 1500: loss 2.268506\n","iteration 200 / 1500: loss 2.092297\n","iteration 300 / 1500: loss 2.067895\n","iteration 400 / 1500: loss 2.073462\n","iteration 500 / 1500: loss 2.066388\n","iteration 600 / 1500: loss 2.162364\n","iteration 700 / 1500: loss 2.049400\n","iteration 800 / 1500: loss 2.055191\n","iteration 900 / 1500: loss 2.050232\n","iteration 1000 / 1500: loss 2.051743\n","iteration 1100 / 1500: loss 2.034316\n","iteration 1200 / 1500: loss 2.132872\n","iteration 1300 / 1500: loss 2.067095\n","iteration 1400 / 1500: loss 2.096036\n","learning rate: 1e-06, regularization: 25000.0\n","iteration 0 / 1500: loss 773.986121\n","iteration 100 / 1500: loss 2.091800\n","iteration 200 / 1500: loss 2.038346\n","iteration 300 / 1500: loss 2.109930\n","iteration 400 / 1500: loss 2.154655\n","iteration 500 / 1500: loss 2.085895\n","iteration 600 / 1500: loss 2.095500\n","iteration 700 / 1500: loss 2.072263\n","iteration 800 / 1500: loss 2.063111\n","iteration 900 / 1500: loss 2.105060\n","iteration 1000 / 1500: loss 2.054013\n","iteration 1100 / 1500: loss 2.144576\n","iteration 1200 / 1500: loss 2.115132\n","iteration 1300 / 1500: loss 2.080030\n","iteration 1400 / 1500: loss 2.100180\n","learning rate: 1e-06, regularization: 30000.0\n","iteration 0 / 1500: loss 938.630138\n","iteration 100 / 1500: loss 2.046178\n","iteration 200 / 1500: loss 2.079489\n","iteration 300 / 1500: loss 2.102532\n","iteration 400 / 1500: loss 2.099498\n","iteration 500 / 1500: loss 2.145544\n","iteration 600 / 1500: loss 2.108331\n","iteration 700 / 1500: loss 2.106782\n","iteration 800 / 1500: loss 2.072993\n","iteration 900 / 1500: loss 2.119087\n","iteration 1000 / 1500: loss 2.120100\n","iteration 1100 / 1500: loss 2.135394\n","iteration 1200 / 1500: loss 2.077876\n","iteration 1300 / 1500: loss 2.119985\n","iteration 1400 / 1500: loss 2.080774\n","learning rate: 1e-06, regularization: 35000.0\n","iteration 0 / 1500: loss 1083.546536\n","iteration 100 / 1500: loss 2.147557\n","iteration 200 / 1500: loss 2.144636\n","iteration 300 / 1500: loss 2.128652\n","iteration 400 / 1500: loss 2.100511\n","iteration 500 / 1500: loss 2.101806\n","iteration 600 / 1500: loss 2.110022\n","iteration 700 / 1500: loss 2.152689\n","iteration 800 / 1500: loss 2.104348\n","iteration 900 / 1500: loss 2.128881\n","iteration 1000 / 1500: loss 2.149107\n","iteration 1100 / 1500: loss 2.170225\n","iteration 1200 / 1500: loss 2.110532\n","iteration 1300 / 1500: loss 2.120314\n","iteration 1400 / 1500: loss 2.129291\n","learning rate: 1e-06, regularization: 40000.0\n","iteration 0 / 1500: loss 1231.957085\n","iteration 100 / 1500: loss 2.130848\n","iteration 200 / 1500: loss 2.121452\n","iteration 300 / 1500: loss 2.145287\n","iteration 400 / 1500: loss 2.118385\n","iteration 500 / 1500: loss 2.183635\n","iteration 600 / 1500: loss 2.158300\n","iteration 700 / 1500: loss 2.119528\n","iteration 800 / 1500: loss 2.069577\n","iteration 900 / 1500: loss 2.124771\n","iteration 1000 / 1500: loss 2.191566\n","iteration 1100 / 1500: loss 2.153080\n","iteration 1200 / 1500: loss 2.109582\n","iteration 1300 / 1500: loss 2.152449\n","iteration 1400 / 1500: loss 2.114444\n","learning rate: 1e-06, regularization: 45000.0\n","iteration 0 / 1500: loss 1377.342090\n","iteration 100 / 1500: loss 2.175531\n","iteration 200 / 1500: loss 2.150817\n","iteration 300 / 1500: loss 2.158951\n","iteration 400 / 1500: loss 2.109411\n","iteration 500 / 1500: loss 2.152426\n","iteration 600 / 1500: loss 2.162664\n","iteration 700 / 1500: loss 2.103125\n","iteration 800 / 1500: loss 2.159934\n","iteration 900 / 1500: loss 2.119700\n","iteration 1000 / 1500: loss 2.145980\n","iteration 1100 / 1500: loss 2.161030\n","iteration 1200 / 1500: loss 2.179402\n","iteration 1300 / 1500: loss 2.183840\n","iteration 1400 / 1500: loss 2.088183\n","learning rate: 1e-06, regularization: 50000.0\n","iteration 0 / 1500: loss 1515.016750\n","iteration 100 / 1500: loss 2.162021\n","iteration 200 / 1500: loss 2.142624\n","iteration 300 / 1500: loss 2.101726\n","iteration 400 / 1500: loss 2.143547\n","iteration 500 / 1500: loss 2.168836\n","iteration 600 / 1500: loss 2.090689\n","iteration 700 / 1500: loss 2.188314\n","iteration 800 / 1500: loss 2.151757\n","iteration 900 / 1500: loss 2.149440\n","iteration 1000 / 1500: loss 2.152170\n","iteration 1100 / 1500: loss 2.153490\n","iteration 1200 / 1500: loss 2.139745\n","iteration 1300 / 1500: loss 2.133435\n","iteration 1400 / 1500: loss 2.111454\n","learning rate: 1e-06, regularization: 60000.0\n","iteration 0 / 1500: loss 1831.370909\n","iteration 100 / 1500: loss 2.177898\n","iteration 200 / 1500: loss 2.210628\n","iteration 300 / 1500: loss 2.167040\n","iteration 400 / 1500: loss 2.148063\n","iteration 500 / 1500: loss 2.198324\n","iteration 600 / 1500: loss 2.162714\n","iteration 700 / 1500: loss 2.197573\n","iteration 800 / 1500: loss 2.164112\n","iteration 900 / 1500: loss 2.200833\n","iteration 1000 / 1500: loss 2.146144\n","iteration 1100 / 1500: loss 2.168892\n","iteration 1200 / 1500: loss 2.165335\n","iteration 1300 / 1500: loss 2.144321\n","iteration 1400 / 1500: loss 2.140412\n","learning rate: 1e-05, regularization: 20000.0\n","iteration 0 / 1500: loss 617.082314\n","iteration 100 / 1500: loss 8.066504\n","iteration 200 / 1500: loss 6.241499\n","iteration 300 / 1500: loss 7.060557\n","iteration 400 / 1500: loss 6.635706\n","iteration 500 / 1500: loss 7.239024\n","iteration 600 / 1500: loss 7.974908\n","iteration 700 / 1500: loss 5.666050\n","iteration 800 / 1500: loss 7.343311\n","iteration 900 / 1500: loss 5.263087\n","iteration 1000 / 1500: loss 7.814371\n","iteration 1100 / 1500: loss 6.721611\n","iteration 1200 / 1500: loss 5.228924\n","iteration 1300 / 1500: loss 8.243802\n","iteration 1400 / 1500: loss 6.020312\n","learning rate: 1e-05, regularization: 25000.0\n","iteration 0 / 1500: loss 785.245947\n","iteration 100 / 1500: loss 7.561973\n","iteration 200 / 1500: loss 8.790173\n","iteration 300 / 1500: loss 10.144663\n","iteration 400 / 1500: loss 5.104404\n","iteration 500 / 1500: loss 6.925048\n","iteration 600 / 1500: loss 6.601276\n","iteration 700 / 1500: loss 5.888372\n","iteration 800 / 1500: loss 6.925558\n","iteration 900 / 1500: loss 6.864453\n","iteration 1000 / 1500: loss 8.483862\n","iteration 1100 / 1500: loss 8.057501\n","iteration 1200 / 1500: loss 8.522491\n","iteration 1300 / 1500: loss 7.357296\n","iteration 1400 / 1500: loss 6.943707\n","learning rate: 1e-05, regularization: 30000.0\n","iteration 0 / 1500: loss 930.200756\n","iteration 100 / 1500: loss 7.117727\n","iteration 200 / 1500: loss 5.775725\n","iteration 300 / 1500: loss 8.753348\n","iteration 400 / 1500: loss 10.433109\n","iteration 500 / 1500: loss 8.999618\n","iteration 600 / 1500: loss 9.631679\n","iteration 700 / 1500: loss 8.665126\n","iteration 800 / 1500: loss 12.469615\n","iteration 900 / 1500: loss 8.038096\n","iteration 1000 / 1500: loss 9.822883\n","iteration 1100 / 1500: loss 8.027309\n","iteration 1200 / 1500: loss 9.829819\n","iteration 1300 / 1500: loss 9.324286\n","iteration 1400 / 1500: loss 9.194882\n","learning rate: 1e-05, regularization: 35000.0\n","iteration 0 / 1500: loss 1079.882203\n","iteration 100 / 1500: loss 10.870272\n","iteration 200 / 1500: loss 11.307146\n","iteration 300 / 1500: loss 8.796349\n","iteration 400 / 1500: loss 8.719052\n","iteration 500 / 1500: loss 10.945218\n","iteration 600 / 1500: loss 11.076678\n","iteration 700 / 1500: loss 10.492590\n","iteration 800 / 1500: loss 12.140498\n","iteration 900 / 1500: loss 10.465741\n","iteration 1000 / 1500: loss 9.359005\n","iteration 1100 / 1500: loss 10.153172\n","iteration 1200 / 1500: loss 10.549510\n","iteration 1300 / 1500: loss 8.920012\n","iteration 1400 / 1500: loss 9.250930\n","learning rate: 1e-05, regularization: 40000.0\n","iteration 0 / 1500: loss 1249.915026\n","iteration 100 / 1500: loss 14.427839\n","iteration 200 / 1500: loss 11.142933\n","iteration 300 / 1500: loss 14.207730\n","iteration 400 / 1500: loss 12.410345\n","iteration 500 / 1500: loss 12.774103\n","iteration 600 / 1500: loss 12.666538\n","iteration 700 / 1500: loss 11.151624\n","iteration 800 / 1500: loss 13.121353\n","iteration 900 / 1500: loss 12.379485\n","iteration 1000 / 1500: loss 14.428555\n","iteration 1100 / 1500: loss 10.918970\n","iteration 1200 / 1500: loss 12.019339\n","iteration 1300 / 1500: loss 13.074152\n","iteration 1400 / 1500: loss 11.606958\n","learning rate: 1e-05, regularization: 45000.0\n","iteration 0 / 1500: loss 1408.297414\n","iteration 100 / 1500: loss 15.708135\n","iteration 200 / 1500: loss 12.633321\n","iteration 300 / 1500: loss 15.183331\n","iteration 400 / 1500: loss 13.188332\n","iteration 500 / 1500: loss 12.818358\n","iteration 600 / 1500: loss 14.725907\n","iteration 700 / 1500: loss 11.903926\n","iteration 800 / 1500: loss 11.369591\n","iteration 900 / 1500: loss 13.040948\n","iteration 1000 / 1500: loss 13.139188\n","iteration 1100 / 1500: loss 12.611725\n","iteration 1200 / 1500: loss 11.266726\n","iteration 1300 / 1500: loss 14.482969\n","iteration 1400 / 1500: loss 11.875296\n","learning rate: 1e-05, regularization: 50000.0\n","iteration 0 / 1500: loss 1560.212575\n","iteration 100 / 1500: loss 15.750245\n","iteration 200 / 1500: loss 15.265145\n","iteration 300 / 1500: loss 14.942206\n","iteration 400 / 1500: loss 16.573881\n","iteration 500 / 1500: loss 14.180518\n","iteration 600 / 1500: loss 16.461951\n","iteration 700 / 1500: loss 14.061802\n","iteration 800 / 1500: loss 18.311307\n","iteration 900 / 1500: loss 15.173605\n","iteration 1000 / 1500: loss 21.511658\n","iteration 1100 / 1500: loss 16.371389\n","iteration 1200 / 1500: loss 18.526661\n","iteration 1300 / 1500: loss 15.760882\n","iteration 1400 / 1500: loss 15.867179\n","learning rate: 1e-05, regularization: 60000.0\n","iteration 0 / 1500: loss 1833.843645\n","iteration 100 / 1500: loss 22.905201\n","iteration 200 / 1500: loss 24.551097\n","iteration 300 / 1500: loss 25.494805\n","iteration 400 / 1500: loss 24.210061\n","iteration 500 / 1500: loss 22.679995\n","iteration 600 / 1500: loss 29.215839\n","iteration 700 / 1500: loss 22.881236\n","iteration 800 / 1500: loss 24.891127\n","iteration 900 / 1500: loss 23.924915\n","iteration 1000 / 1500: loss 26.138805\n","iteration 1100 / 1500: loss 24.193495\n","iteration 1200 / 1500: loss 21.617943\n","iteration 1300 / 1500: loss 23.690690\n","iteration 1400 / 1500: loss 23.809267\n","learning rate: 0.0001, regularization: 20000.0\n","iteration 0 / 1500: loss 617.764071\n"],"name":"stdout"},{"output_type":"stream","text":["/content/cs231n/classifiers/softmax.py:81: RuntimeWarning: divide by zero encountered in log\n","  loss = -np.log(softmax[np.arange(num_train),y]).sum()\n"],"name":"stderr"},{"output_type":"stream","text":["iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n"],"name":"stdout"},{"output_type":"stream","text":["/content/cs231n/classifiers/softmax.py:83: RuntimeWarning: overflow encountered in double_scalars\n","  loss += reg * np.sum(W * W)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n","  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n","/content/cs231n/classifiers/softmax.py:83: RuntimeWarning: overflow encountered in multiply\n","  loss += reg * np.sum(W * W)\n"],"name":"stderr"},{"output_type":"stream","text":["iteration 400 / 1500: loss inf\n","iteration 500 / 1500: loss inf\n","iteration 600 / 1500: loss inf\n"],"name":"stdout"},{"output_type":"stream","text":["/content/cs231n/classifiers/softmax.py:79: RuntimeWarning: overflow encountered in subtract\n","  scores -= np.max(scores, axis=1, keepdims=True)  # avoid numerical instability\n","/content/cs231n/classifiers/softmax.py:79: RuntimeWarning: invalid value encountered in subtract\n","  scores -= np.max(scores, axis=1, keepdims=True)  # avoid numerical instability\n","/content/cs231n/classifiers/softmax.py:87: RuntimeWarning: overflow encountered in multiply\n","  dW += 2 * reg * W\n"],"name":"stderr"},{"output_type":"stream","text":["iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 25000.0\n","iteration 0 / 1500: loss 783.255760\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss inf\n","iteration 500 / 1500: loss inf\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 30000.0\n","iteration 0 / 1500: loss 915.456043\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss inf\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 35000.0\n","iteration 0 / 1500: loss 1070.496853\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 40000.0\n","iteration 0 / 1500: loss 1228.331288\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 45000.0\n","iteration 0 / 1500: loss 1384.831653\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 50000.0\n","iteration 0 / 1500: loss 1518.724972\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 60000.0\n","iteration 0 / 1500: loss 1835.870456\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss nan\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 1e-05, regularization: 20000.0\n","iteration 0 / 1500: loss 618.236032\n","iteration 100 / 1500: loss 4.993227\n","iteration 200 / 1500: loss 7.234594\n","iteration 300 / 1500: loss 5.272362\n","iteration 400 / 1500: loss 5.816931\n","iteration 500 / 1500: loss 6.592449\n","iteration 600 / 1500: loss 4.329244\n","iteration 700 / 1500: loss 7.224898\n","iteration 800 / 1500: loss 6.244612\n","iteration 900 / 1500: loss 5.101171\n","iteration 1000 / 1500: loss 7.556668\n","iteration 1100 / 1500: loss 6.162261\n","iteration 1200 / 1500: loss 5.884049\n","iteration 1300 / 1500: loss 5.583202\n","iteration 1400 / 1500: loss 5.715269\n","learning rate: 1e-05, regularization: 25000.0\n","iteration 0 / 1500: loss 772.936221\n","iteration 100 / 1500: loss 7.516318\n","iteration 200 / 1500: loss 6.741297\n","iteration 300 / 1500: loss 8.844617\n","iteration 400 / 1500: loss 9.454751\n","iteration 500 / 1500: loss 8.356413\n","iteration 600 / 1500: loss 7.777979\n","iteration 700 / 1500: loss 6.570646\n","iteration 800 / 1500: loss 7.429895\n","iteration 900 / 1500: loss 9.390685\n","iteration 1000 / 1500: loss 6.605311\n","iteration 1100 / 1500: loss 7.035117\n","iteration 1200 / 1500: loss 7.803131\n","iteration 1300 / 1500: loss 7.597487\n","iteration 1400 / 1500: loss 8.984608\n","learning rate: 1e-05, regularization: 30000.0\n","iteration 0 / 1500: loss 935.848817\n","iteration 100 / 1500: loss 9.892787\n","iteration 200 / 1500: loss 8.573963\n","iteration 300 / 1500: loss 6.956905\n","iteration 400 / 1500: loss 8.924348\n","iteration 500 / 1500: loss 7.281846\n","iteration 600 / 1500: loss 6.953995\n","iteration 700 / 1500: loss 11.031403\n","iteration 800 / 1500: loss 11.977829\n","iteration 900 / 1500: loss 13.469632\n","iteration 1000 / 1500: loss 9.384774\n","iteration 1100 / 1500: loss 9.315462\n","iteration 1200 / 1500: loss 11.311399\n","iteration 1300 / 1500: loss 10.542628\n","iteration 1400 / 1500: loss 9.779271\n","learning rate: 1e-05, regularization: 35000.0\n","iteration 0 / 1500: loss 1084.396207\n","iteration 100 / 1500: loss 11.043917\n","iteration 200 / 1500: loss 10.259180\n","iteration 300 / 1500: loss 12.072165\n","iteration 400 / 1500: loss 8.444889\n","iteration 500 / 1500: loss 10.897318\n","iteration 600 / 1500: loss 9.838236\n","iteration 700 / 1500: loss 11.663514\n","iteration 800 / 1500: loss 10.255501\n","iteration 900 / 1500: loss 11.433906\n","iteration 1000 / 1500: loss 8.610700\n","iteration 1100 / 1500: loss 10.676490\n","iteration 1200 / 1500: loss 10.640192\n","iteration 1300 / 1500: loss 11.181612\n","iteration 1400 / 1500: loss 12.025709\n","learning rate: 1e-05, regularization: 40000.0\n","iteration 0 / 1500: loss 1251.691360\n","iteration 100 / 1500: loss 11.405030\n","iteration 200 / 1500: loss 12.048279\n","iteration 300 / 1500: loss 10.548096\n","iteration 400 / 1500: loss 8.408938\n","iteration 500 / 1500: loss 11.071425\n","iteration 600 / 1500: loss 13.479459\n","iteration 700 / 1500: loss 11.520997\n","iteration 800 / 1500: loss 11.849080\n","iteration 900 / 1500: loss 8.684298\n","iteration 1000 / 1500: loss 11.128325\n","iteration 1100 / 1500: loss 10.344724\n","iteration 1200 / 1500: loss 8.650976\n","iteration 1300 / 1500: loss 10.054581\n","iteration 1400 / 1500: loss 12.337150\n","learning rate: 1e-05, regularization: 45000.0\n","iteration 0 / 1500: loss 1394.586263\n","iteration 100 / 1500: loss 14.822291\n","iteration 200 / 1500: loss 12.681738\n","iteration 300 / 1500: loss 12.481100\n","iteration 400 / 1500: loss 12.417905\n","iteration 500 / 1500: loss 15.103047\n","iteration 600 / 1500: loss 13.941085\n","iteration 700 / 1500: loss 10.531572\n","iteration 800 / 1500: loss 13.898138\n","iteration 900 / 1500: loss 13.801219\n","iteration 1000 / 1500: loss 12.284835\n","iteration 1100 / 1500: loss 12.457056\n","iteration 1200 / 1500: loss 12.530013\n","iteration 1300 / 1500: loss 13.768348\n","iteration 1400 / 1500: loss 13.855974\n","learning rate: 1e-05, regularization: 50000.0\n","iteration 0 / 1500: loss 1536.813594\n","iteration 100 / 1500: loss 15.139642\n","iteration 200 / 1500: loss 14.568320\n","iteration 300 / 1500: loss 15.811187\n","iteration 400 / 1500: loss 15.045785\n","iteration 500 / 1500: loss 18.385474\n","iteration 600 / 1500: loss 14.902512\n","iteration 700 / 1500: loss 17.451130\n","iteration 800 / 1500: loss 14.793104\n","iteration 900 / 1500: loss 17.057419\n","iteration 1000 / 1500: loss 15.475005\n","iteration 1100 / 1500: loss 18.007512\n","iteration 1200 / 1500: loss 15.785248\n","iteration 1300 / 1500: loss 16.035226\n","iteration 1400 / 1500: loss 18.885049\n","learning rate: 1e-05, regularization: 60000.0\n","iteration 0 / 1500: loss 1872.743067\n","iteration 100 / 1500: loss 26.341876\n","iteration 200 / 1500: loss 28.145426\n","iteration 300 / 1500: loss 26.157277\n","iteration 400 / 1500: loss 25.254270\n","iteration 500 / 1500: loss 27.867679\n","iteration 600 / 1500: loss 29.026660\n","iteration 700 / 1500: loss 28.988657\n","iteration 800 / 1500: loss 23.478105\n","iteration 900 / 1500: loss 23.176435\n","iteration 1000 / 1500: loss 23.962053\n","iteration 1100 / 1500: loss 26.887166\n","iteration 1200 / 1500: loss 25.695345\n","iteration 1300 / 1500: loss 24.311426\n","iteration 1400 / 1500: loss 25.396130\n","learning rate: 0.0001, regularization: 20000.0\n","iteration 0 / 1500: loss 622.111336\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss inf\n","iteration 500 / 1500: loss inf\n","iteration 600 / 1500: loss inf\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 25000.0\n","iteration 0 / 1500: loss 778.011685\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss inf\n","iteration 500 / 1500: loss inf\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 30000.0\n","iteration 0 / 1500: loss 922.352563\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss inf\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 35000.0\n","iteration 0 / 1500: loss 1084.587418\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 40000.0\n","iteration 0 / 1500: loss 1219.181548\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 45000.0\n","iteration 0 / 1500: loss 1382.747462\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 50000.0\n","iteration 0 / 1500: loss 1563.943391\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss inf\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","learning rate: 0.0001, regularization: 60000.0\n","iteration 0 / 1500: loss 1833.911896\n","iteration 100 / 1500: loss inf\n","iteration 200 / 1500: loss inf\n","iteration 300 / 1500: loss nan\n","iteration 400 / 1500: loss nan\n","iteration 500 / 1500: loss nan\n","iteration 600 / 1500: loss nan\n","iteration 700 / 1500: loss nan\n","iteration 800 / 1500: loss nan\n","iteration 900 / 1500: loss nan\n","iteration 1000 / 1500: loss nan\n","iteration 1100 / 1500: loss nan\n","iteration 1200 / 1500: loss nan\n","iteration 1300 / 1500: loss nan\n","iteration 1400 / 1500: loss nan\n","lr 1.000000e-09 reg 2.000000e+04 train accuracy: 0.134551 val accuracy: 0.129000\n","lr 1.000000e-09 reg 2.500000e+04 train accuracy: 0.116163 val accuracy: 0.112000\n","lr 1.000000e-09 reg 3.000000e+04 train accuracy: 0.091449 val accuracy: 0.089000\n","lr 1.000000e-09 reg 3.500000e+04 train accuracy: 0.088612 val accuracy: 0.094000\n","lr 1.000000e-09 reg 4.000000e+04 train accuracy: 0.107776 val accuracy: 0.120000\n","lr 1.000000e-09 reg 4.500000e+04 train accuracy: 0.135163 val accuracy: 0.134000\n","lr 1.000000e-09 reg 5.000000e+04 train accuracy: 0.086592 val accuracy: 0.081000\n","lr 1.000000e-09 reg 6.000000e+04 train accuracy: 0.119776 val accuracy: 0.110000\n","lr 1.000000e-08 reg 2.000000e+04 train accuracy: 0.197776 val accuracy: 0.210000\n","lr 1.000000e-08 reg 2.500000e+04 train accuracy: 0.162408 val accuracy: 0.170000\n","lr 1.000000e-08 reg 3.000000e+04 train accuracy: 0.174449 val accuracy: 0.171000\n","lr 1.000000e-08 reg 3.500000e+04 train accuracy: 0.179939 val accuracy: 0.166000\n","lr 1.000000e-08 reg 4.000000e+04 train accuracy: 0.192224 val accuracy: 0.181000\n","lr 1.000000e-08 reg 4.500000e+04 train accuracy: 0.181755 val accuracy: 0.188000\n","lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.217898 val accuracy: 0.246000\n","lr 1.000000e-08 reg 6.000000e+04 train accuracy: 0.233429 val accuracy: 0.249000\n","lr 1.000000e-07 reg 2.000000e+04 train accuracy: 0.334000 val accuracy: 0.345000\n","lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.327755 val accuracy: 0.342000\n","lr 1.000000e-07 reg 3.000000e+04 train accuracy: 0.322816 val accuracy: 0.342000\n","lr 1.000000e-07 reg 3.500000e+04 train accuracy: 0.317204 val accuracy: 0.330000\n","lr 1.000000e-07 reg 4.000000e+04 train accuracy: 0.312286 val accuracy: 0.326000\n","lr 1.000000e-07 reg 4.500000e+04 train accuracy: 0.314898 val accuracy: 0.324000\n","lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.311143 val accuracy: 0.328000\n","lr 1.000000e-07 reg 6.000000e+04 train accuracy: 0.303122 val accuracy: 0.318000\n","lr 1.000000e-06 reg 2.000000e+04 train accuracy: 0.334878 val accuracy: 0.347000\n","lr 1.000000e-06 reg 2.500000e+04 train accuracy: 0.321204 val accuracy: 0.333000\n","lr 1.000000e-06 reg 3.000000e+04 train accuracy: 0.321816 val accuracy: 0.327000\n","lr 1.000000e-06 reg 3.500000e+04 train accuracy: 0.312959 val accuracy: 0.324000\n","lr 1.000000e-06 reg 4.000000e+04 train accuracy: 0.300980 val accuracy: 0.327000\n","lr 1.000000e-06 reg 4.500000e+04 train accuracy: 0.301551 val accuracy: 0.311000\n","lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.306143 val accuracy: 0.302000\n","lr 1.000000e-06 reg 6.000000e+04 train accuracy: 0.277327 val accuracy: 0.291000\n","lr 1.000000e-05 reg 2.000000e+04 train accuracy: 0.161796 val accuracy: 0.151000\n","lr 1.000000e-05 reg 2.500000e+04 train accuracy: 0.129980 val accuracy: 0.137000\n","lr 1.000000e-05 reg 3.000000e+04 train accuracy: 0.168551 val accuracy: 0.165000\n","lr 1.000000e-05 reg 3.500000e+04 train accuracy: 0.124776 val accuracy: 0.120000\n","lr 1.000000e-05 reg 4.000000e+04 train accuracy: 0.084224 val accuracy: 0.084000\n","lr 1.000000e-05 reg 4.500000e+04 train accuracy: 0.077633 val accuracy: 0.078000\n","lr 1.000000e-05 reg 5.000000e+04 train accuracy: 0.110041 val accuracy: 0.100000\n","lr 1.000000e-05 reg 6.000000e+04 train accuracy: 0.109122 val accuracy: 0.109000\n","lr 1.000000e-04 reg 2.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 2.500000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 3.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 3.500000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 4.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 4.500000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 5.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","lr 1.000000e-04 reg 6.000000e+04 train accuracy: 0.100265 val accuracy: 0.087000\n","best validation accuracy achieved during cross-validation: 0.347000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"test","executionInfo":{"status":"ok","timestamp":1602624401130,"user_tz":-180,"elapsed":1139,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"ecb24053-5dc1-4412-c179-54d87730c3bd","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluate on test set\n","# Evaluate the best softmax on test set\n","y_test_pred = best_softmax.predict(X_test)\n","test_accuracy = np.mean(y_test == y_test_pred)\n","print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["softmax on raw pixels final test set accuracy: 0.349000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"tags":["pdf-inline"],"id":"NVre2Pr10b-6"},"source":["**Inline Question 2** - *True or False*\n","\n","Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n","\n","$\\color{blue}{\\textit Your Answer:}$ True\n","\n","\n","$\\color{blue}{\\textit Your Explanation:}$ A new datapoint will not increase the SVM loss (i.e., hinge-loss will yield zero) when the correct score is larger than any other class score + the margin. If this condition is met, than the datapoint will add zero to the overall loss. However, with softmax loss, the loss is calculated by -log(prob) of the correct class. Even if the correct class is substantially larger than the other classes, it will still add something to the overall loss. \n","\n"]},{"cell_type":"code","metadata":{"id":"04YTxwth0b-7","executionInfo":{"status":"ok","timestamp":1602625275549,"user_tz":-180,"elapsed":1138,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}},"outputId":"8ff4fd39-2e09-4b35-b74c-e568826dce05","colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["# Visualize the learned weights for each class\n","w = best_softmax.W[:-1,:] # strip out the bias\n","w = w.reshape(32, 32, 3, 10)\n","\n","w_min, w_max = np.min(w), np.max(w)\n","\n","classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","for i in range(10):\n","    plt.subplot(2, 5, i + 1)\n","    \n","    # Rescale the weights to be between 0 and 255\n","    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n","    plt.imshow(wimg.astype('uint8'))\n","    plt.axis('off')\n","    plt.title(classes[i])"],"execution_count":46,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 10 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"pxTw_xRi0b_G"},"source":["---\n","# IMPORTANT\n","\n","This is the end of this question. Please do the following:\n","\n","1. Click `File -> Save` to make sure the latest checkpoint of this notebook is saved to your Drive.\n","2. Execute the cell below to download the modified `.py` files back to your drive."]},{"cell_type":"code","metadata":{"id":"dg4xp5-_0b_I","executionInfo":{"status":"ok","timestamp":1602625425270,"user_tz":-180,"elapsed":703,"user":{"displayName":"Erez Wasserman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGiPtCPKIzKyPPfvbZH7HYw7ndjPA3Gmj0onXE_E0=s64","userId":"01230727903402681209"}}},"source":["import os\n","\n","FOLDER_TO_SAVE = os.path.join('drive/My Drive/', FOLDERNAME)\n","FILES_TO_SAVE = ['cs231n/classifiers/softmax.py']\n","\n","for files in FILES_TO_SAVE:\n","  with open(os.path.join(FOLDER_TO_SAVE, '/'.join(files.split('/')[1:])), 'w') as f:\n","    f.write(''.join(open(files).readlines()))"],"execution_count":47,"outputs":[]}]}